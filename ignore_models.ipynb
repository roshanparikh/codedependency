{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4f1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score, fbeta_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875e439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/90_day_mort.csv')\n",
    "y = df.copy()['target']\n",
    "X = df.copy().drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ad59d",
   "metadata": {},
   "source": [
    "**MULTIPLE MODEL GRID SEARCH CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb79d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Organization\n",
    "'''\n",
    "\n",
    "names_cat_feats = ['admission_type', 'admit_provider_id', 'admission_location',\n",
    "       'insurance', 'language', 'marital_status', 'race', 'gender', 'first_careunit', \n",
    "       'last_careunit']\n",
    "names_cont_feats = ['anchor_age', 'los',\n",
    "       'Absolute Basophil Count', 'Absolute Eosinophil Count',\n",
    "       'Absolute Lymphocyte Count', 'Absolute Monocyte Count',\n",
    "       'Absolute Neutrophil Count', 'Anion Gap', 'Base Excess', 'Bicarbonate',\n",
    "       'Calculated Total CO2', 'Creatinine', 'H', 'Hematocrit', 'Hemoglobin',\n",
    "       'I', 'INR(PT)', 'Immature Granulocytes', 'L', 'Lactate', 'PT', 'PTT',\n",
    "       'Platelet Count', 'RDW', 'Red Blood Cells', 'SIRI', 'Urea Nitrogen',\n",
    "       'pO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Defining imputers\n",
    "'''\n",
    "\n",
    "onehot_ftrs = names_cat_feats\n",
    "std_ftrs = names_cont_feats\n",
    "\n",
    "# Categorical\n",
    "one_hot_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# Standard scaler \n",
    "std_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('std', std_transformer, std_ftrs),\n",
    "        ('ohot', one_hot_transformer, onehot_ftrs)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "final_scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60efd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Parameter grid\n",
    "'''\n",
    "\n",
    "random_state = 42; max_iter = 1000000\n",
    "\n",
    "models_and_params = {\n",
    "    'Ridge': {'model': LogisticRegression(penalty = 'l2', random_state=random_state, max_iter=max_iter),\n",
    "              'params': {'logisticregression__C': np.logspace(-8, 3, 12),\n",
    "                         'logisticregression__class_weight': ['balanced', None]}\n",
    "    },\n",
    "    'KNN': {'model': KNeighborsClassifier(),\n",
    "            'params': {'kneighborsclassifier__n_neighbors': [3, 5, 7, 10, 15, 30, 50, 70, 100],\n",
    "                       'kneighborsclassifier__weights': ['uniform', 'distance'],\n",
    "                       'kneighborsclassifier__p': [1,2]} #1 is Manhattan distance, 2 is Euclidean distance \n",
    "    },\n",
    "    'SVC Linear': {'model': SVC(kernel = 'linear', random_state=random_state),\n",
    "                   'params': {'svc__C': np.logspace(-5, 3, 9),\n",
    "                              'svc__class_weight': ['balanced', None]}\n",
    "    },\n",
    "    'SVC RBF': {'model': SVC(kernel = 'rbf', random_state=random_state),\n",
    "                'params': {'svc__C': np.logspace(-5, 3, 9),\n",
    "                           'svc__class_weight': ['balanced', None]}\n",
    "    }, \n",
    "    'XGB': {'model': XGBClassifier(learning_rate = 0.03, n_estimators = 1000, missing=np.nan, subsample=0.66),\n",
    "            'params': {'xgbclassifier__max_depth': [1, 3, 10, 30, 100],  # Depth of the tree\n",
    "                       'xgbclassifier__colsample_bytree': [0.1, 0.25, 0.5, 0.75, 1.0],  # Fraction of features used for fitting trees\n",
    "                       'xgbclassifier__scale_pos_weight': [0.025, 0.05, 0.1, 0.25, 0.5, 1, 5, 10]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Creating pipeline\n",
    "'''\n",
    "\n",
    "def MLpipe_StratKFold(X, y, preprocessor, ML_algo, param_grid):\n",
    "    results = {}\n",
    "    baseline_accuracy = []\n",
    "\n",
    "    for i in range(5):\n",
    "        iterative_imputer = IterativeImputer(max_iter=10, random_state=42*i)\n",
    "\n",
    "        # Split Data\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X,y, train_size=0.8,random_state = 42*i)\n",
    "\n",
    "        majority_class = np.bincount(y_test).argmax()\n",
    "        y_baseline = [majority_class] * len(y_test)\n",
    "        baseline_accuracy.append(accuracy_score(y_test, y_baseline))\n",
    "\n",
    "        if ML_algo != 'XGB':\n",
    "            pipe = make_pipeline(preprocessor, iterative_imputer, StandardScaler(),ML_algo)\n",
    "        else:\n",
    "            pipe = make_pipeline(preprocessor, StandardScaler(),ML_algo)\n",
    "\n",
    "        # CV and prepro\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(f1_score),\n",
    "                                cv=None, return_train_score = True, n_jobs=-1, verbose=False)\n",
    "\n",
    "        grid.fit(X_other, y_other)\n",
    "        y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "        transformer = grid.best_estimator_['columntransformer']\n",
    "        X_test_prep = transformer.transform(X_test)\n",
    "        X_test_prep_df = pd.DataFrame(X_test_prep, columns = transformer.get_feature_names_out())\n",
    "\n",
    "        results[i] = {\n",
    "            'X_test [not preprocessed]': X_test,\n",
    "            'X_test [preprocessed]': X_test_prep_df,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred,\n",
    "            'test_score': accuracy_score(y_test, y_pred),\n",
    "            'f_1_score': fbeta_score(y_test, y_pred, beta=1),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'best_model': grid.best_estimator_,\n",
    "            'best_params': grid.best_params_\n",
    "        }\n",
    "\n",
    "    results['baseline_accuracy'] = {\n",
    "        'baseline_avg': np.mean(baseline_accuracy),\n",
    "        'baseline_std': np.std(baseline_accuracy)\n",
    "    }\n",
    "\n",
    "    baseline = results['baseline_accuracy']['baseline_avg']\n",
    "\n",
    "    for i in range(5):\n",
    "        results[i]['relative_improvement'] = (results[i]['test_score'] - baseline)/baseline\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Performing grid search.\n",
    "'''\n",
    "models = ['XGB', 'KNN', 'Ridge', 'SVC Linear', 'SVC RBF']\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model in models:\n",
    "    ML_algo = models_and_params[model]['model']\n",
    "    params = models_and_params[model]['params']\n",
    "    \n",
    "    print(f\"Results for {model}\")\n",
    "    results = MLpipe_StratKFold(X, y, preprocessor=preprocessor, ML_algo=ML_algo, param_grid=params)\n",
    "\n",
    "    # To print for each random_state\n",
    "    scores = []\n",
    "    for i in range(5):\n",
    "        print(f\"Results for Random State {i}\")\n",
    "        print(f\"  Test Score: {results[i]['test_score']}\")\n",
    "        print(f\"  f1 Score: {results[i]['f_1_score']}\")\n",
    "        print(f\"    precision: {results[i]['precision']}\")\n",
    "        print(f\"    recall: {results[i]['recall']}\")\n",
    "        print(f\"  Baseline: {results['baseline_accuracy']['baseline_avg']}, Relative Accuracy: {results[i]['relative_improvement']}\")\n",
    "        print(f\"  Baseline Standard Deviation: {results['baseline_accuracy']['baseline_std']}\")\n",
    "        print(f\"  Best Params: {results[i]['best_params']}\")\n",
    "        scores.append(results[i]['test_score'])\n",
    "\n",
    "    print(f\"Mean of Test Scores: {np.mean(scores)}\")\n",
    "    print(f\"Standard Deviation of Test Scores: {np.std(scores)}\")\n",
    "    print(\"=========\")\n",
    "\n",
    "    model_results[model] = results\n",
    "\n",
    "# Save entire dictionary as pickle\n",
    "\n",
    "with open('model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(model_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating f_beta score\n",
    "f1 = []\n",
    "for i in range(5):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X,y, train_size=0.8,random_state = 42*i)\n",
    "    y_0 = np.ones_like(y_test)\n",
    "    f1.append(fbeta_score(y_test, y_0, beta=1))\n",
    "\n",
    "baseline_f1 = np.mean(f1) \n",
    "print(f\" {baseline_f1} +/- {np.std(f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_results.pkl', 'rb') as f:\n",
    "    model_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919db3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Saving models and data.\n",
    "'''\n",
    "\n",
    "for model in ['Ridge', 'KNN', 'SVC Linear','SVC RBF', 'XGB']:\n",
    "    for i in range(5):\n",
    "        # Save test sets as CSV\n",
    "        X_test_tbs = model_results[model][i]['X_test [not preprocessed]']\n",
    "        X_test_prep_tbs = model_results[model][i]['X_test [preprocessed]']\n",
    "        y_test_tbs = model_results[model][i]['y_test'].reset_index(drop=True)\n",
    "\n",
    "        X_test_tbs.to_csv(f'{model}_X_test_{i}.csv', index=False)\n",
    "\n",
    "        X_test_prep_tbs.to_csv(f'{model}_X_test_prep_{i}.csv', index=False)\n",
    "\n",
    "        y_test_tbs_df = pd.DataFrame(y_test_tbs.values, columns=['y_test'])\n",
    "        y_test_tbs_df.to_csv(f'{model}_y_test_{i}.csv', index=False)\n",
    "\n",
    "        # Save models\n",
    "        mymodel = model_results[model][i]['best_model'][-1]\n",
    "        with open(f'{model}_{i}_trained', 'wb') as f:\n",
    "            pickle.dump(mymodel, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7dc468",
   "metadata": {},
   "source": [
    "**RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fee842",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data\n",
    "'''\n",
    "with open(f\"model_results.pkl\", 'rb') as file:\n",
    "        model_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd711d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Average and Std of Test Scores for all models.\n",
    "''' \n",
    "model_test_scores = {}\n",
    "model_f1_scores = {}\n",
    "\n",
    "for model in ['Ridge', 'KNN', 'SVC Linear', 'SVC RBF', 'XGB']:\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    mymodel = model_results[model]\n",
    "    for i in range(5):\n",
    "        test_scores.append(mymodel[i]['relative_improvement'])\n",
    "        f1_scores.append(mymodel[i]['f_1_score'])\n",
    "    model_test_scores[model] = {\n",
    "        'average': np.mean(test_scores),\n",
    "        'std': np.std(test_scores)\n",
    "    }\n",
    "\n",
    "    model_f1_scores[model] = {\n",
    "        'average': np.mean(f1_scores),\n",
    "        'std': np.std(f1_scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting average and std for accuracy and f1 scores\n",
    "print(f\"accuracy {model_test_scores}\")\n",
    "print(f\"f1 scores {model_f1_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathon25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
